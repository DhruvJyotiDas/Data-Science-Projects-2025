{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2965251,"sourceType":"datasetVersion","datasetId":1817999}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/dhruvjyotidas1000/vit-small?scriptVersionId=286584633\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# I trained a pretrained DeiT ViT, converted images into patch embeddings, used self-attention to model global context, and fine-tuned it using AdamW with ImageNet normalization.","metadata":{}},{"cell_type":"code","source":"!pip install -q timm\n# timm provides all the transformers here \n#timm = pre-trained models, torch = DL ka engine\n\nimport timm, torch\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:17:32.215678Z","iopub.execute_input":"2025-12-16T10:17:32.216247Z","iopub.status.idle":"2025-12-16T10:18:49.353607Z","shell.execute_reply.started":"2025-12-16T10:17:32.216222Z","shell.execute_reply":"2025-12-16T10:18:49.352894Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"path = \"/kaggle/input/vegetable-image-dataset/Vegetable Images/train\"\ntransform = transforms.Compose([transforms.Resize((224,224)),\n                                transforms.ToTensor(),\n                                transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])\n\ntrain = datasets.ImageFolder(path, transform=transform) # Load images from folders (folder = class)\nloader = DataLoader(train, batch_size=32, shuffle=True)\nclasses = train.classes\n#Image ko 224Ã—224 karna image ko tensor mai convert karna and normalizing pixels with imagenet images mean and stuff","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:19:37.235605Z","iopub.execute_input":"2025-12-16T10:19:37.236114Z","iopub.status.idle":"2025-12-16T10:20:33.964452Z","shell.execute_reply.started":"2025-12-16T10:19:37.236085Z","shell.execute_reply":"2025-12-16T10:20:33.963763Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"model = timm.create_model(\n    \"deit_base_patch16_224\",\n    pretrained=True,\n    num_classes=len(classes)\n)\n\nmodel = model.cuda()\n\nif torch.cuda.device_count() > 1:\n    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n    model = torch.nn.DataParallel(model)\n\n# Hum DeiT model use kar rahe hain jo actually ViT ka data-efficient version hai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:20:37.340303Z","iopub.execute_input":"2025-12-16T10:20:37.341081Z","iopub.status.idle":"2025-12-16T10:20:42.18669Z","shell.execute_reply.started":"2025-12-16T10:20:37.341055Z","shell.execute_reply":"2025-12-16T10:20:42.186032Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5055aff7c7a94f2cba672ebc9a488ea9"}},"metadata":{}},{"name":"stdout","text":"Using 2 GPUs\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"opt = torch.optim.AdamW(model.parameters(), lr=3e-5)\nloss_fn = nn.CrossEntropyLoss()\n#Transformer ko train karne ka recommended optimizer and Standard classification loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:20:54.260255Z","iopub.execute_input":"2025-12-16T10:20:54.26059Z","iopub.status.idle":"2025-12-16T10:20:54.265712Z","shell.execute_reply.started":"2025-12-16T10:20:54.260566Z","shell.execute_reply":"2025-12-16T10:20:54.26501Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"for epoch in range(5):   \n    for x, y in loader:\n        x, y = x.cuda(), y.cuda()\n        opt.zero_grad()\n        out = model(x)\n        loss = loss_fn(out, y)\n        loss.backward()\n        opt.step()\n    print(\"Epoch\", epoch+1, \"done\")\n# around 15-20 mins","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:20:57.694737Z","iopub.execute_input":"2025-12-16T10:20:57.695013Z","iopub.status.idle":"2025-12-16T10:46:20.891934Z","shell.execute_reply.started":"2025-12-16T10:20:57.69499Z","shell.execute_reply":"2025-12-16T10:46:20.891206Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 done\nEpoch 2 done\nEpoch 3 done\nEpoch 4 done\nEpoch 5 done\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"torch.save(model.module.state_dict(), \"vit_veg_best.pth\")\n\n# Saving trained model weights after all 5 epochs are done","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:57:40.132016Z","iopub.execute_input":"2025-12-16T10:57:40.132741Z","iopub.status.idle":"2025-12-16T10:57:40.486194Z","shell.execute_reply.started":"2025-12-16T10:57:40.132716Z","shell.execute_reply":"2025-12-16T10:57:40.485444Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from PIL import Image\n\ndef predict(img_path):\n    img = Image.open(img_path).convert(\"RGB\")\n    t = transform(img).unsqueeze(0).cuda()\n    with torch.no_grad():\n        p = model(t).softmax(1)[0]\n    return classes[p.argmax().item()], float(p.max().item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:57:43.781772Z","iopub.execute_input":"2025-12-16T10:57:43.782422Z","iopub.status.idle":"2025-12-16T10:57:43.786657Z","shell.execute_reply.started":"2025-12-16T10:57:43.782398Z","shell.execute_reply":"2025-12-16T10:57:43.78591Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"predict(\"/kaggle/input/vegetable-image-dataset/Vegetable Images/train/Tomato/0001.jpg\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T10:58:40.622345Z","iopub.execute_input":"2025-12-16T10:58:40.622901Z","iopub.status.idle":"2025-12-16T10:58:40.771637Z","shell.execute_reply.started":"2025-12-16T10:58:40.622876Z","shell.execute_reply":"2025-12-16T10:58:40.771034Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"('Tomato', 0.9997316002845764)"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"I trained a pretrained DeiT-based Vision Transformer on a custom vegetable dataset and validated the inference pipeline successfully. Next, I plan to compare frozen-backbone, partial fine-tuning, and parameter-efficient adaptation strategies","metadata":{}},{"cell_type":"code","source":"path = \"/kaggle/input/vegetable-image-dataset/Vegetable Images/train\"\n\ntransform = transforms.Compose([\n    transforms.Resize((224,224)),       # Image ko ViT size me lana\n    transforms.ToTensor(),               # Image â†’ Tensor\n    transforms.Normalize(                # ImageNet normalization\n        [0.485,0.456,0.406],\n        [0.229,0.224,0.225]\n    )\n])\n\ntrain = datasets.ImageFolder(path, transform=transform)\nloader = DataLoader(train, batch_size=64, shuffle=True)\n\nclasses = train.classes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:13:25.833472Z","iopub.execute_input":"2025-12-16T11:13:25.834083Z","iopub.status.idle":"2025-12-16T11:13:46.31917Z","shell.execute_reply.started":"2025-12-16T11:13:25.834057Z","shell.execute_reply":"2025-12-16T11:13:46.318168Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model = timm.create_model(\n    \"deit_base_patch16_224\",\n    pretrained=True,     # ImageNet se seekha hua model\n    num_classes=len(classes)\n).cuda()\n# Baseline wala model reuse mat karo.\n#Hamesha fresh model for new experiment.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:19:13.160237Z","iopub.execute_input":"2025-12-16T11:19:13.160574Z","iopub.status.idle":"2025-12-16T11:19:14.750306Z","shell.execute_reply.started":"2025-12-16T11:19:13.160553Z","shell.execute_reply":"2025-12-16T11:19:14.749683Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:19:19.720303Z","iopub.execute_input":"2025-12-16T11:19:19.720574Z","iopub.status.idle":"2025-12-16T11:19:19.725387Z","shell.execute_reply.started":"2025-12-16T11:19:19.720554Z","shell.execute_reply":"2025-12-16T11:19:19.724697Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"for param in model.head.parameters():\n    param.requires_grad = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:19:23.510122Z","iopub.execute_input":"2025-12-16T11:19:23.510739Z","iopub.status.idle":"2025-12-16T11:19:23.514156Z","shell.execute_reply.started":"2025-12-16T11:19:23.510715Z","shell.execute_reply":"2025-12-16T11:19:23.513535Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"opt = torch.optim.AdamW(\n    model.head.parameters(),  # sirf head update hoga\n    lr=1e-3                   # head ke liye high LR\n)\n\nloss_fn = nn.CrossEntropyLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:19:28.720151Z","iopub.execute_input":"2025-12-16T11:19:28.720844Z","iopub.status.idle":"2025-12-16T11:19:28.724671Z","shell.execute_reply.started":"2025-12-16T11:19:28.720817Z","shell.execute_reply":"2025-12-16T11:19:28.72394Z"}},"outputs":[],"execution_count":23},{"cell_type":"markdown","source":"learning sirf head me ho rahi","metadata":{}},{"cell_type":"code","source":"for epoch in range(5):\n    for x,y in loader:\n        x,y = x.cuda(),y.cuda()\n        opt.zero_grad()\n        out=model(x)\n        loss=loss_fn(out,y)\n        loss.backward()\n        opt.step()\n    print(\"Epochs {Epoch+1} done\")    \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:19:30.99985Z","iopub.execute_input":"2025-12-16T11:19:31.000553Z","iopub.status.idle":"2025-12-16T11:34:21.06674Z","shell.execute_reply.started":"2025-12-16T11:19:31.000522Z","shell.execute_reply":"2025-12-16T11:34:21.066093Z"}},"outputs":[{"name":"stdout","text":"Epochs {Epoch+1} done\nEpochs {Epoch+1} done\nEpochs {Epoch+1} done\nEpochs {Epoch+1} done\nEpochs {Epoch+1} done\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"torch.save(model.state_dict(), \"vit_frozen_head.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:50:35.140089Z","iopub.execute_input":"2025-12-16T11:50:35.140881Z","iopub.status.idle":"2025-12-16T11:50:35.513405Z","shell.execute_reply.started":"2025-12-16T11:50:35.140852Z","shell.execute_reply":"2025-12-16T11:50:35.51249Z"}},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"# Partial Fine-tuning (Last Transformer Blocks + Head)\nSirf last 2 transformer blocks + head trainable","metadata":{}},{"cell_type":"code","source":"model = timm.create_model(\n    \"deit_base_patch16_224\",\n    pretrained=True,\n    num_classes=len(classes)\n).cuda()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:52:46.710918Z","iopub.execute_input":"2025-12-16T11:52:46.711475Z","iopub.status.idle":"2025-12-16T11:52:48.186921Z","shell.execute_reply.started":"2025-12-16T11:52:46.711452Z","shell.execute_reply":"2025-12-16T11:52:48.186284Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:52:56.345009Z","iopub.execute_input":"2025-12-16T11:52:56.345296Z","iopub.status.idle":"2025-12-16T11:52:56.349483Z","shell.execute_reply.started":"2025-12-16T11:52:56.345247Z","shell.execute_reply":"2025-12-16T11:52:56.348789Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# DeiT / ViT me transformer blocks model.blocks me hote hain\nfor block in model.blocks[-2:]:   # last 2 blocks\n    for param in block.parameters():\n        param.requires_grad = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:53:05.170307Z","iopub.execute_input":"2025-12-16T11:53:05.170986Z","iopub.status.idle":"2025-12-16T11:53:05.174606Z","shell.execute_reply.started":"2025-12-16T11:53:05.170963Z","shell.execute_reply":"2025-12-16T11:53:05.173964Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"for param in model.head.parameters():\n    param.requires_grad = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:53:12.594854Z","iopub.execute_input":"2025-12-16T11:53:12.595079Z","iopub.status.idle":"2025-12-16T11:53:12.598657Z","shell.execute_reply.started":"2025-12-16T11:53:12.595064Z","shell.execute_reply":"2025-12-16T11:53:12.597891Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"opt = torch.optim.AdamW(\n    filter(lambda p: p.requires_grad, model.parameters()),\n    lr=1e-4   # partial finetune = medium LR\n)\n\nloss_fn = nn.CrossEntropyLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:53:20.845219Z","iopub.execute_input":"2025-12-16T11:53:20.845494Z","iopub.status.idle":"2025-12-16T11:53:20.850409Z","shell.execute_reply.started":"2025-12-16T11:53:20.845473Z","shell.execute_reply":"2025-12-16T11:53:20.849823Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"for epoch in range(5):\n    for x, y in loader:\n        x, y = x.cuda(), y.cuda()\n        opt.zero_grad()\n        out = model(x)\n        loss = loss_fn(out, y)\n        loss.backward()\n        opt.step()\n    print(f\"Epoch {epoch+1} done\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T11:53:30.600488Z","iopub.execute_input":"2025-12-16T11:53:30.600753Z","iopub.status.idle":"2025-12-16T12:12:50.983157Z","shell.execute_reply.started":"2025-12-16T11:53:30.600733Z","shell.execute_reply":"2025-12-16T12:12:50.981935Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 done\nEpoch 2 done\nEpoch 3 done\nEpoch 4 done\nEpoch 5 done\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"torch.save(model.state_dict(), \"vit_partial_finetune.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:20:36.001572Z","iopub.execute_input":"2025-12-16T12:20:36.002104Z","iopub.status.idle":"2025-12-16T12:20:36.358788Z","shell.execute_reply.started":"2025-12-16T12:20:36.00208Z","shell.execute_reply":"2025-12-16T12:20:36.358161Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"# Original + Custom NN (Custom Head)","metadata":{}},{"cell_type":"code","source":"model = timm.create_model(\n    \"deit_base_patch16_224\",\n    pretrained=True,\n    num_classes=len(classes)  # temporary, abhi replace karenge\n).cuda()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:23:07.274767Z","iopub.execute_input":"2025-12-16T12:23:07.275364Z","iopub.status.idle":"2025-12-16T12:23:08.750623Z","shell.execute_reply.started":"2025-12-16T12:23:07.27534Z","shell.execute_reply":"2025-12-16T12:23:08.750035Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:23:12.934683Z","iopub.execute_input":"2025-12-16T12:23:12.935294Z","iopub.status.idle":"2025-12-16T12:23:12.939228Z","shell.execute_reply.started":"2025-12-16T12:23:12.935247Z","shell.execute_reply":"2025-12-16T12:23:12.938523Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"in_features = model.head.in_features\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:23:19.175458Z","iopub.execute_input":"2025-12-16T12:23:19.176037Z","iopub.status.idle":"2025-12-16T12:23:19.179332Z","shell.execute_reply.started":"2025-12-16T12:23:19.176014Z","shell.execute_reply":"2025-12-16T12:23:19.178425Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"model.head = nn.Sequential(\n    nn.Linear(in_features, 512),  # thoda compression\n    nn.ReLU(),                    # non-linearity\n    nn.Dropout(0.3),              # overfitting kam\n    nn.Linear(512, len(classes))  # final classes\n).cuda()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:23:24.185434Z","iopub.execute_input":"2025-12-16T12:23:24.186097Z","iopub.status.idle":"2025-12-16T12:23:24.19439Z","shell.execute_reply.started":"2025-12-16T12:23:24.186071Z","shell.execute_reply":"2025-12-16T12:23:24.193814Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"for param in model.head.parameters():\n    param.requires_grad = True\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:23:32.215324Z","iopub.execute_input":"2025-12-16T12:23:32.216042Z","iopub.status.idle":"2025-12-16T12:23:32.21951Z","shell.execute_reply.started":"2025-12-16T12:23:32.216021Z","shell.execute_reply":"2025-12-16T12:23:32.218764Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"opt = torch.optim.AdamW(\n    model.head.parameters(),\n    lr=1e-3   # head ke liye high LR\n)\n\nloss_fn = nn.CrossEntropyLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:23:38.765141Z","iopub.execute_input":"2025-12-16T12:23:38.765882Z","iopub.status.idle":"2025-12-16T12:23:38.76996Z","shell.execute_reply.started":"2025-12-16T12:23:38.765858Z","shell.execute_reply":"2025-12-16T12:23:38.769365Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"for epoch in range(5):\n    for x, y in loader:\n        x, y = x.cuda(), y.cuda()\n        opt.zero_grad()\n        out = model(x)\n        loss = loss_fn(out, y)\n        loss.backward()\n        opt.step()\n    print(f\"Epoch {epoch+1} done\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:23:45.60066Z","iopub.execute_input":"2025-12-16T12:23:45.600923Z","iopub.status.idle":"2025-12-16T12:38:36.073113Z","shell.execute_reply.started":"2025-12-16T12:23:45.600902Z","shell.execute_reply":"2025-12-16T12:38:36.072422Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 done\nEpoch 2 done\nEpoch 3 done\nEpoch 4 done\nEpoch 5 done\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"torch.save(model.state_dict(), \"vit_custom_head.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:38:47.520418Z","iopub.execute_input":"2025-12-16T12:38:47.520705Z","iopub.status.idle":"2025-12-16T12:38:47.883617Z","shell.execute_reply.started":"2025-12-16T12:38:47.520684Z","shell.execute_reply":"2025-12-16T12:38:47.883044Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"# Finetuned-LoRA (parameter-efficient fine-tuning)","metadata":{}},{"cell_type":"markdown","source":"ViT backbone freeze + Attention layers me LoRA adapters + sirf LoRA train","metadata":{}},{"cell_type":"markdown","source":"Ab LoRA kyun next hai? (simple Hinglish)\n\nAb tak tum weights ko directly train kar rahe the\n\nLoRA me:\n\nOriginal ViT weights â„ï¸ frozen\n\nSirf chhote adapter matrices train ðŸ”¥\n\nMatlab:\n\nKam parameters\n\nKam GPU usage\n\nModern research approach","metadata":{}},{"cell_type":"code","source":"!pip install -q timm peft\nimport timm, torch\nimport torch.nn as nn\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\n\nfrom peft import LoraConfig, get_peft_model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:47:04.319807Z","iopub.execute_input":"2025-12-16T12:47:04.32056Z","iopub.status.idle":"2025-12-16T12:47:34.593617Z","shell.execute_reply.started":"2025-12-16T12:47:04.320527Z","shell.execute_reply":"2025-12-16T12:47:34.592941Z"}},"outputs":[{"name":"stderr","text":"2025-12-16 12:47:14.576439: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765889234.820277      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765889234.884726      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":43},{"cell_type":"code","source":"path = \"/kaggle/input/vegetable-image-dataset/Vegetable Images/train\"\n\ntransform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        [0.485,0.456,0.406],\n        [0.229,0.224,0.225]\n    )\n])\n\ntrain = datasets.ImageFolder(path, transform=transform)\nloader = DataLoader(train, batch_size=64, shuffle=True)\n\nclasses = train.classes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:47:58.88547Z","iopub.execute_input":"2025-12-16T12:47:58.885659Z","iopub.status.idle":"2025-12-16T12:47:59.00872Z","shell.execute_reply.started":"2025-12-16T12:47:58.885643Z","shell.execute_reply":"2025-12-16T12:47:59.007933Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"model = timm.create_model(\n    \"deit_base_patch16_224\",\n    pretrained=True,\n    num_classes=len(classes)\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:48:40.145189Z","iopub.execute_input":"2025-12-16T12:48:40.145773Z","iopub.status.idle":"2025-12-16T12:48:41.641071Z","shell.execute_reply.started":"2025-12-16T12:48:40.145748Z","shell.execute_reply":"2025-12-16T12:48:41.640299Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=8,                    # rank (small = efficient)\n    lora_alpha=16,          # scaling factor\n    target_modules=[\"qkv\"], # ViT attention ke andar\n    lora_dropout=0.1,\n    bias=\"none\"\n)\n# r = LoRA kitna powerful hoga\n\n#qkv = attention ka heart (Query, Key, Value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:48:47.715182Z","iopub.execute_input":"2025-12-16T12:48:47.715755Z","iopub.status.idle":"2025-12-16T12:48:47.719449Z","shell.execute_reply.started":"2025-12-16T12:48:47.715729Z","shell.execute_reply":"2025-12-16T12:48:47.718655Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"model = get_peft_model(model, lora_config)\nmodel = model.cuda()\nmodel.print_trainable_parameters()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:48:53.149745Z","iopub.execute_input":"2025-12-16T12:48:53.150351Z","iopub.status.idle":"2025-12-16T12:48:53.273085Z","shell.execute_reply.started":"2025-12-16T12:48:53.150323Z","shell.execute_reply":"2025-12-16T12:48:53.272461Z"}},"outputs":[{"name":"stdout","text":"trainable params: 294,912 || all params: 86,105,103 || trainable%: 0.3425\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"opt = torch.optim.AdamW(\n    model.parameters(),   # sirf LoRA params actually update honge\n    lr=1e-4\n)\n\nloss_fn = nn.CrossEntropyLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:49:22.940669Z","iopub.execute_input":"2025-12-16T12:49:22.941358Z","iopub.status.idle":"2025-12-16T12:49:22.945964Z","shell.execute_reply.started":"2025-12-16T12:49:22.941333Z","shell.execute_reply":"2025-12-16T12:49:22.945222Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"for epoch in range(5):\n    for x, y in loader:\n        x, y = x.cuda(), y.cuda()\n        opt.zero_grad()\n        out = model(x)\n        loss = loss_fn(out, y)\n        loss.backward()\n        opt.step()\n    print(f\"Epoch {epoch+1} done\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T12:49:24.795018Z","iopub.execute_input":"2025-12-16T12:49:24.795597Z","iopub.status.idle":"2025-12-16T13:22:21.846193Z","shell.execute_reply.started":"2025-12-16T12:49:24.795566Z","shell.execute_reply":"2025-12-16T13:22:21.845359Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 done\nEpoch 2 done\nEpoch 3 done\nEpoch 4 done\nEpoch 5 done\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"torch.save(model.state_dict(), \"vit_lora.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T13:28:14.805531Z","iopub.execute_input":"2025-12-16T13:28:14.805862Z","iopub.status.idle":"2025-12-16T13:28:15.175248Z","shell.execute_reply.started":"2025-12-16T13:28:14.805841Z","shell.execute_reply":"2025-12-16T13:28:15.174664Z"}},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":"# âœ” original vit\n# âœ” original + custom nn\n# âœ” finetune\n# âœ” partial finetune\n# âœ” finetuned-LoRA â† DONE","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\n\ntest_path = \"/kaggle/input/vegetable-image-dataset/Vegetable Images/test\"\n\ntransform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        [0.485,0.456,0.406],\n        [0.229,0.224,0.225]\n    )\n])\n\ntest_data = datasets.ImageFolder(test_path, transform=transform)\ntest_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n\nclasses = test_data.classes\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T13:30:10.475316Z","iopub.execute_input":"2025-12-16T13:30:10.475645Z","iopub.status.idle":"2025-12-16T13:30:21.030379Z","shell.execute_reply.started":"2025-12-16T13:30:10.475622Z","shell.execute_reply":"2025-12-16T13:30:21.029718Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"import torch\n\ndef evaluate_accuracy(model, loader):\n    model.eval()\n    correct, total = 0, 0\n\n    with torch.no_grad():\n        for x, y in loader:\n            x, y = x.cuda(), y.cuda()\n            out = model(x)\n            preds = out.argmax(dim=1)\n            correct += (preds == y).sum().item()\n            total += y.size(0)\n\n    return correct / total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T13:30:30.55528Z","iopub.execute_input":"2025-12-16T13:30:30.555558Z","iopub.status.idle":"2025-12-16T13:30:30.560162Z","shell.execute_reply.started":"2025-12-16T13:30:30.555539Z","shell.execute_reply":"2025-12-16T13:30:30.559483Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"def count_trainable_params(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T13:31:04.785438Z","iopub.execute_input":"2025-12-16T13:31:04.785732Z","iopub.status.idle":"2025-12-16T13:31:04.78945Z","shell.execute_reply.started":"2025-12-16T13:31:04.785711Z","shell.execute_reply":"2025-12-16T13:31:04.788781Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"# MODEL LOADER ----\nimport timm\nimport torch.nn as nn\n\ndef load_vit_model(weight_path, model_type):\n    model = timm.create_model(\n        \"deit_base_patch16_224\",\n        pretrained=False,\n        num_classes=len(classes)\n    )\n\n    # Custom head case\n    if model_type == \"custom_head\":\n        in_features = model.head.in_features\n        model.head = nn.Sequential(\n            nn.Linear(in_features, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, len(classes))\n        )\n\n    model.load_state_dict(torch.load(weight_path))\n    model = model.cuda()\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T13:31:07.09513Z","iopub.execute_input":"2025-12-16T13:31:07.095893Z","iopub.status.idle":"2025-12-16T13:31:07.10067Z","shell.execute_reply.started":"2025-12-16T13:31:07.095867Z","shell.execute_reply":"2025-12-16T13:31:07.099957Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"models_info = {\n    \"Full Fine-tune\": (\"vit_veg_best.pth\", \"normal\"),\n    \"Frozen Head\": (\"vit_frozen_head.pth\", \"normal\"),\n    \"Partial Fine-tune\": (\"vit_partial_finetune.pth\", \"normal\"),\n    \"Custom Head\": (\"vit_custom_head.pth\", \"custom_head\"),\n}\n\nresults = []\n\nfor name, (path, mtype) in models_info.items():\n    model = load_vit_model(path, mtype)\n    acc = evaluate_accuracy(model, test_loader)\n    params = count_trainable_params(model)\n\n    results.append((name, acc, params))\n    print(f\"{name} | Accuracy: {acc:.4f} | Trainable Params: {params}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T13:31:09.84513Z","iopub.execute_input":"2025-12-16T13:31:09.845819Z","iopub.status.idle":"2025-12-16T13:34:02.535696Z","shell.execute_reply.started":"2025-12-16T13:31:09.845793Z","shell.execute_reply":"2025-12-16T13:34:02.534958Z"}},"outputs":[{"name":"stdout","text":"Full Fine-tune | Accuracy: 1.0000 | Trainable Params: 85810191\nFrozen Head | Accuracy: 0.9987 | Trainable Params: 85810191\nPartial Fine-tune | Accuracy: 1.0000 | Trainable Params: 85810191\nCustom Head | Accuracy: 0.9987 | Trainable Params: 86200079\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n\n# Fresh base model\nmodel = timm.create_model(\n    \"deit_base_patch16_224\",\n    pretrained=False,\n    num_classes=len(classes)\n)\n\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"qkv\"],\n    lora_dropout=0.1,\n    bias=\"none\"\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.load_state_dict(torch.load(\"vit_lora.pth\"))\nmodel = model.cuda()\n\nlora_acc = evaluate_accuracy(model, test_loader)\nlora_params = count_trainable_params(model)\n\nprint(f\"LoRA | Accuracy: {lora_acc:.4f} | Trainable Params: {lora_params}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T13:35:11.935032Z","iopub.execute_input":"2025-12-16T13:35:11.935452Z","iopub.status.idle":"2025-12-16T13:35:52.474997Z","shell.execute_reply.started":"2025-12-16T13:35:11.935428Z","shell.execute_reply":"2025-12-16T13:35:52.474293Z"}},"outputs":[{"name":"stdout","text":"LoRA | Accuracy: 0.9997 | Trainable Params: 294912\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"print(\"\\nFINAL COMPARISON\\n\")\n\nfor r in results:\n    print(f\"{r[0]:20s} | Acc: {r[1]:.4f} | Params: {r[2]}\")\n\nprint(f\"{'LoRA':20s} | Acc: {lora_acc:.4f} | Params: {lora_params}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-16T13:36:30.78555Z","iopub.execute_input":"2025-12-16T13:36:30.785828Z","iopub.status.idle":"2025-12-16T13:36:30.790579Z","shell.execute_reply.started":"2025-12-16T13:36:30.785794Z","shell.execute_reply":"2025-12-16T13:36:30.78982Z"}},"outputs":[{"name":"stdout","text":"\nFINAL COMPARISON\n\nFull Fine-tune       | Acc: 1.0000 | Params: 85810191\nFrozen Head          | Acc: 0.9987 | Params: 85810191\nPartial Fine-tune    | Acc: 1.0000 | Params: 85810191\nCustom Head          | Acc: 0.9987 | Params: 86200079\nLoRA                 | Acc: 0.9997 | Params: 294912\n","output_type":"stream"}],"execution_count":65}]}